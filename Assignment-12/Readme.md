*********************************************************************************************

Max Accuracy= 40.13%



*********************************************************************************************


Logs:-


*********************************************************************************************


 
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 64, 64]           1,728
       BatchNorm2d-2           [-1, 64, 64, 64]             128
            Conv2d-3           [-1, 64, 64, 64]          36,864
       BatchNorm2d-4           [-1, 64, 64, 64]             128
            Conv2d-5           [-1, 64, 64, 64]          36,864
       BatchNorm2d-6           [-1, 64, 64, 64]             128
        BasicBlock-7           [-1, 64, 64, 64]               0
            Conv2d-8           [-1, 64, 64, 64]          36,864
       BatchNorm2d-9           [-1, 64, 64, 64]             128
           Conv2d-10           [-1, 64, 64, 64]          36,864
      BatchNorm2d-11           [-1, 64, 64, 64]             128
       BasicBlock-12           [-1, 64, 64, 64]               0
           Conv2d-13          [-1, 128, 32, 32]          73,728
      BatchNorm2d-14          [-1, 128, 32, 32]             256
           Conv2d-15          [-1, 128, 32, 32]         147,456
      BatchNorm2d-16          [-1, 128, 32, 32]             256
           Conv2d-17          [-1, 128, 32, 32]           8,192
      BatchNorm2d-18          [-1, 128, 32, 32]             256
       BasicBlock-19          [-1, 128, 32, 32]               0
           Conv2d-20          [-1, 128, 32, 32]         147,456
      BatchNorm2d-21          [-1, 128, 32, 32]             256
           Conv2d-22          [-1, 128, 32, 32]         147,456
      BatchNorm2d-23          [-1, 128, 32, 32]             256
       BasicBlock-24          [-1, 128, 32, 32]               0
           Conv2d-25          [-1, 256, 16, 16]         294,912
      BatchNorm2d-26          [-1, 256, 16, 16]             512
           Conv2d-27          [-1, 256, 16, 16]         589,824
      BatchNorm2d-28          [-1, 256, 16, 16]             512
           Conv2d-29          [-1, 256, 16, 16]          32,768
      BatchNorm2d-30          [-1, 256, 16, 16]             512
       BasicBlock-31          [-1, 256, 16, 16]               0
           Conv2d-32          [-1, 256, 16, 16]         589,824
      BatchNorm2d-33          [-1, 256, 16, 16]             512
           Conv2d-34          [-1, 256, 16, 16]         589,824
      BatchNorm2d-35          [-1, 256, 16, 16]             512
       BasicBlock-36          [-1, 256, 16, 16]               0
           Conv2d-37            [-1, 512, 8, 8]       1,179,648
      BatchNorm2d-38            [-1, 512, 8, 8]           1,024
           Conv2d-39            [-1, 512, 8, 8]       2,359,296
      BatchNorm2d-40            [-1, 512, 8, 8]           1,024
           Conv2d-41            [-1, 512, 8, 8]         131,072
      BatchNorm2d-42            [-1, 512, 8, 8]           1,024
       BasicBlock-43            [-1, 512, 8, 8]               0
           Conv2d-44            [-1, 512, 8, 8]       2,359,296
      BatchNorm2d-45            [-1, 512, 8, 8]           1,024
           Conv2d-46            [-1, 512, 8, 8]       2,359,296
      BatchNorm2d-47            [-1, 512, 8, 8]           1,024
       BasicBlock-48            [-1, 512, 8, 8]               0
           Linear-49                  [-1, 200]         102,600
================================================================
Total params: 11,271,432
Trainable params: 11,271,432
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.05
Forward/backward pass size (MB): 45.00
Params size (MB): 43.00
Estimated Total Size (MB): 88.05
----------------------------------------------------------------
EPOCH: 0 LR: 0.0009999999999999992 
Loss=4.036650657653809 Batch_id=531 le=0.0018468899783472149 Accuracy=4.94: 100%|██████████| 532/532 [41:28<00:00,  4.68s/it]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0349, Accuracy: 2301/28771 (8.00%)

EPOCH: 1 LR: 0.0018468899783472149 
Loss=4.153738021850586 Batch_id=531 le=0.004068794297644442 Accuracy=12.02: 100%|██████████| 532/532 [06:26<00:00,  1.37it/s]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0324, Accuracy: 3453/28771 (12.00%)

EPOCH: 2 LR: 0.004068794297644442 
Loss=3.3608908653259277 Batch_id=531 le=0.006829398068620918 Accuracy=18.40: 100%|██████████| 532/532 [06:26<00:00,  1.38it/s]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0304, Accuracy: 4530/28771 (15.75%)

EPOCH: 3 LR: 0.006829398068620918 
Loss=3.0129799842834473 Batch_id=531 le=0.00908962232779775 Accuracy=24.53: 100%|██████████| 532/532 [06:26<00:00,  1.38it/s]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0266, Accuracy: 6473/28771 (22.50%)

EPOCH: 4 LR: 0.00908962232779775 
Loss=3.4604196548461914 Batch_id=531 le=0.009998728731213106 Accuracy=30.90: 100%|██████████| 532/532 [06:25<00:00,  1.38it/s]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0282, Accuracy: 6093/28771 (21.18%)

EPOCH: 5 LR: 0.009998728731213106 
Loss=2.2723946571350098 Batch_id=531 le=0.009936630432037444 Accuracy=36.35: 100%|██████████| 532/532 [06:28<00:00,  1.37it/s]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0237, Accuracy: 8705/28771 (30.26%)

EPOCH: 6 LR: 0.009936630432037444 
Loss=3.0681040287017822 Batch_id=531 le=0.009738136088096358 Accuracy=41.64: 100%|██████████| 532/532 [06:29<00:00,  1.36it/s]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0224, Accuracy: 9660/28771 (33.58%)

EPOCH: 7 LR: 0.009738136088096358 
Loss=1.8574508428573608 Batch_id=531 le=0.009409854453666896 Accuracy=46.56: 100%|██████████| 532/532 [06:28<00:00,  1.37it/s]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0206, Accuracy: 10850/28771 (37.71%)

EPOCH: 8 LR: 0.009409854453666896 
Loss=2.206944704055786 Batch_id=531 le=0.00896077793265593 Accuracy=51.07: 100%|██████████| 532/532 [06:25<00:00,  1.38it/s]
  0%|          | 0/532 [00:00<?, ?it/s]
Test set: Average loss: 0.0213, Accuracy: 10520/28771 (36.56%)

EPOCH: 9 LR: 0.00896077793265593 
Loss=1.6683518886566162 Batch_id=531 le=0.00840320778422175 Accuracy=55.85: 100%|██████████| 532/532 [06:28<00:00,  1.37it/s]
Test set: Average loss: 0.0202, Accuracy: 11547/28771 (40.13%)